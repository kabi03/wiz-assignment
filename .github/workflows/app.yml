name: app-build-scan-push-deploy

on:
  pull_request:
    branches: ["main"]
    paths:
      - "tasky-main/**"
      - ".github/workflows/app.yml"
  push:
    branches: ["main"]
    paths:
      - "tasky-main/**"
      - ".github/workflows/app.yml"
  workflow_dispatch: {}

jobs:
  build_scan_push_deploy:
    runs-on: ubuntu-latest

    permissions:
      id-token: write
      contents: read
      security-events: write

    env:
      AWS_REGION: ${{ secrets.AWS_REGION }}
      EKS_CLUSTER_NAME: wiz-exercise
      ECR_REPO: wiz-exercise-tasky
      K8S_NAMESPACE: tasky
      DEPLOYMENT_NAME: tasky
      CONTAINER_NAME: tasky

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Fail fast if required secrets are missing
        run: |
          if [ -z "${{ secrets.AWS_REGION }}" ]; then
            echo "Missing required secret: AWS_REGION"
            exit 1
          fi
          if [ -z "${{ secrets.AWS_ROLE_TO_ASSUME }}" ]; then
            echo "Missing required secret: AWS_ROLE_TO_ASSUME"
            exit 1
          fi
          echo "Secrets look present (values are masked)."

      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}
          aws-region: ${{ secrets.AWS_REGION }}
          audience: sts.amazonaws.com

      - name: Verify AWS identity
        run: aws sts get-caller-identity

      - name: Install Podman
        run: |
          sudo apt-get update
          sudo apt-get install -y podman

      - name: Login to Amazon ECR (Podman)
        run: |
          ACCOUNT_ID="$(aws sts get-caller-identity --query Account --output text)"
          ECR_REGISTRY="${ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com"
          aws ecr get-login-password --region "${AWS_REGION}" \
            | podman login --username AWS --password-stdin "${ECR_REGISTRY}"

      - name: Set image URI
        id: img
        run: |
          ACCOUNT_ID="$(aws sts get-caller-identity --query Account --output text)"
          IMAGE_URI="${ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com/${ECR_REPO}:${GITHUB_SHA}"
          echo "IMAGE_URI=${IMAGE_URI}" >> "$GITHUB_ENV"
          echo "image=${IMAGE_URI}" >> "$GITHUB_OUTPUT"

      - name: Build image (Podman)
        working-directory: tasky-main
        run: |
          podman build -t "${IMAGE_URI}" -f Dockerfile .

      - name: Trivy image scan (report-only)
        uses: aquasecurity/trivy-action@0.28.0
        with:
          image-ref: ${{ steps.img.outputs.image }}
          format: sarif
          output: trivy.sarif
          vuln-type: os,library
          severity: CRITICAL,HIGH
          exit-code: "0"

      - name: Upload Trivy SARIF
        if: >
          github.event_name != 'pull_request' ||
          github.event.pull_request.head.repo.fork == false
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: trivy.sarif

      - name: Push image (Podman)
        run: |
          podman push "${IMAGE_URI}"

      - name: Install kubectl
        uses: azure/setup-kubectl@v4
        with:
          version: v1.29.0

      - name: Update kubeconfig for EKS
        run: aws eks update-kubeconfig --name "${EKS_CLUSTER_NAME}" --region "${AWS_REGION}"

      - name: Deploy updated image
        run: |
          kubectl -n "${K8S_NAMESPACE}" set image "deployment/${DEPLOYMENT_NAME}" \
            "${CONTAINER_NAME}=${IMAGE_URI}"

          kubectl -n "${K8S_NAMESPACE}" rollout status "deployment/${DEPLOYMENT_NAME}" --timeout=300s

      - name: Verify wizexercise.txt exists (robust)
        run: |
          echo "Listing pods + labels for debugging:"
          kubectl -n "${K8S_NAMESPACE}" get pods --show-labels || true

          # Try your expected label selector first
          POD="$(kubectl -n "${K8S_NAMESPACE}" get pods -l app=tasky -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || true)"

          # Fallback: use the deployment's selector labels if app=tasky isn't present
          if [ -z "$POD" ]; then
            echo "No pod found with label app=tasky. Falling back to deployment selector..."
            SELECTOR="$(kubectl -n "${K8S_NAMESPACE}" get deploy "${DEPLOYMENT_NAME}" -o jsonpath='{range $k,$v := .spec.selector.matchLabels}{printf "%s=%s," $k $v}{end}' | sed 's/,$//')"
            echo "Derived selector: ${SELECTOR}"
            POD="$(kubectl -n "${K8S_NAMESPACE}" get pods -l "${SELECTOR}" -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || true)"
          fi

          if [ -z "$POD" ]; then
            echo "ERROR: Could not determine a pod to exec into."
            exit 1
          fi

          echo "Using pod: $POD"
          kubectl -n "${K8S_NAMESPACE}" wait --for=condition=Ready "pod/${POD}" --timeout=120s
          kubectl -n "${K8S_NAMESPACE}" exec "${POD}" -- ls -la /app
          kubectl -n "${K8S_NAMESPACE}" exec "${POD}" -- cat /app/wizexercise.txt
